import streamlit as st
from openai import OpenAI
from docx import Document
from io import BytesIO
import requests
from datetime import datetime
import pytz
import urllib.parse
import tiktoken  # í† í° ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# Streamlitì—ì„œ í™˜ê²½ ë³€ìˆ˜(Secrets) ê°€ì ¸ì˜¤ê¸°
openai_api_key = st.secrets["OPENAI_API_KEY"]

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Doc-Sum + Timezone",
    page_icon="ğŸ“",
)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=openai_api_key)

generation_config = {
    "temperature": 0.4,
    "top_p": 0.95,
}

st.title("Doc-Sum + Timezone")
st.caption("By Phoenix AI")

# 3. Doc-Sum: ë¬¸ì„œ ìš”ì•½ ê¸°ëŠ¥
st.header("Doc-Sum: ë¬¸ì„œ ìš”ì•½ ê¸°ëŠ¥")
uploaded_file_sum = st.file_uploader("ìš”ì•½í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œ í•´ ì£¼ì„¸ìš”", type=["docx"], key="sum_file")

def calculate_tokens(text):
    tokenizer = tiktoken.encoding_for_model("gpt-4")
    tokens = tokenizer.encode(text)
    return len(tokens)

def split_text_by_tokens(text, max_tokens=2000):
    tokenizer = tiktoken.encoding_for_model("gpt-4")
    tokens = tokenizer.encode(text)
    chunks = []
    current_chunk = []
    current_length = 0
    
    for token in tokens:
        current_chunk.append(token)
        current_length += 1
        if current_length >= max_tokens:
            chunks.append(tokenizer.decode(current_chunk))
            current_chunk = []
            current_length = 0
    
    if current_chunk:
        chunks.append(tokenizer.decode(current_chunk))
    
    return chunks

if uploaded_file_sum:
    document = Document(uploaded_file_sum)
    doc_text_sum = "\n".join([para.text for para in document.paragraphs])
    st.header("ë¬¸ì„œ ë‚´ìš© ìš”ì•½")
    
    # ë¬¸ì„œì˜ í† í° ê¸¸ì´ ê³„ì‚°
    total_tokens = calculate_tokens(doc_text_sum)
    
    if total_tokens > 8192:
        st.error(f"ë¬¸ì„œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë¬¸ì„œì˜ ì´ í† í° ìˆ˜: {total_tokens}. ë¬¸ì„œë¥¼ ë¶„í• í•˜ì—¬ ìš”ì•½í•©ë‹ˆë‹¤.")
        chunks = split_text_by_tokens(doc_text_sum)
    else:
        chunks = [doc_text_sum]

    # ìš”ì•½ ìš”ì²­ ì²˜ë¦¬
    for i, chunk in enumerate(chunks):
        st.subheader(f"ë¬¸ì„œ ìš”ì•½ {i+1}/{len(chunks)}")
        if st.button(f"ìš”ì•½ ìƒì„± {i+1}"):
            with st.spinner("ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    response = client.chat.completions.create(
                        model="gpt-4",  # ëª¨ë¸ ì´ë¦„ ê³ ì •
                        messages=[
                            {"role": "system", "content": "Summarize the following document."},
                            {"role": "user", "content": chunk}
                        ],
                        max_tokens=500,
                        temperature=generation_config["temperature"],
                        top_p=generation_config["top_p"]
                    )
                    st.success(response.choices[0].message.content.strip())
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
